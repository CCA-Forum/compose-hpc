---------BLAS TO CUDABLAS TRANSFORMATION README------------

- Environment variables needed:

  PAUL_HOME (path to paul/demo folder),
  BLAS_HOME, MKL_HOME (if using Intel MKL library)

- Works with C++ code too.

- Coccinelle version (1.0.0-rc4) is needed
  for this transformation to work as desired.

- Tranformations involving BLAS level 1,2 routines have not
  been tested so far. The transformed code is not always 
  guaranteed to work as of now.

- Routines in BLAS 1 that return values -> dot*, sum,
  nrm2, amin, amax, rot* need more work and hence are
  not transformed even if annotated.

- If the C interface to BLAS is used and arrays are
  specified to be treated as if in row-major order,
  then the transformation produces a warning for blas calls
  that do not have transpose options as arguments, since CUDA BLAS
  assumes column-major storage of arrays. The user
  could then tweak the generated CUBLAS call to specify
  whether the arrays should be transposed or not.
  

- Some BLAS routines are not provided in CUDA BLAS and
  are hence not handled by this transformation. They are
  - BLAS 3 -> {c,z}gemm3m (handled by using CUDA cgemm,zgemm)
              {SC,DZ}GEMM, {SC,DZ}GEMV (Intel MKL only)
  - BLAS 2 -> {s,d}gem2vu, {c,z}gem2vc 
  - BLAS 1 -> {s}dsdot, {d,s}cabs1 
  - CUDA BLAS library provides routines for rotg, rotmg
    for completeness sake and are run on the CPU. Hence
    they are not transformed even if annotated.

- For users of INTEL MKL library.

  Some types provided in mkl_types.h like
  MKL_Complex8, MKL_Complex16, MKL_INT are not
  recognized by the CUDA BLAS library since they
  are not from the C/C++ standard. So any
  variables/array references that are passed to
  the original (non-transformed) BLAS calls
  should not be of these types. If present,
  it is the user's responsibility to convert
  them into analogous types specified in the 
  C/C++ standard before passing them to the
  original BLAS call.

  - The only type conversion effort required by the 
    user is with complex numbers. CUDA BLAS calls
    use cuComplex and cuDoubleComplex which are 
    defined in cuda/include/cuComplex.h as follows:

	typedef float2 cuFloatComplex;
	typedef cuFloatComplex cuComplex;
	typedef double2 cuDoubleComplex;


  

Annotations Specification
--------------------------

- The annotation required is shown in
the following example.

/*% BLAS_TO_CUBLAS prefix=device1 */
cblas_sgemm(...);

- The value of prefix (device1 in the above annotation)
  indicates the prefix for the array/variable
  names used when introducing new variables
  (for example pointers that hold reference to memory 
  allocated on the GPU) in the transformed code. 
  For now the prefix selection to avoid name clashes
  is left to the user.

Running a sample transformation
-------------------------------
- The script Blas2Cublas.py in paul/demo folder is used
  to run the transformation.

- The options to this script are
  ./Blas2Cublas.py path-to-file BLAS_OPTION autoAnnot 
   where AnnotOptions={autoAnnot, autoAnnotNstop, PAUL} 

  where BLAS_OPTION is one of {MKL,BLAS} which 
  tells the script whether to use the Intel MKL library
  or any other BLAS library.

- The environment variables PAUL_HOME, BLAS_HOME and MKL_HOME are
  required to be set accordingly.

	Adding Annotations automatically
	--------------------------------

	- If the user desires to annotate all the blas calls
	  present in his code, the option autoAnnot (optional)
	  to blas2cublas.py needs to be passed. The script
	  automatically annotates all BLAS calls in the source file
	  provided.

	- The autoAnnotNstop option stops the script after automatically
	  annotating the input source code. If not provided, the script proceeds
	  to generate the transformed code. This option is used when the user
	  wants to verify/add something to the automatically annotated code.

	- After the user verifies/adds something to the automatically annotated code,
	  he can run the script with the option PAUL which would resume the process of
	  generating the transformed code taking the annotated code.
          NOTE: When running with PAUL option the input file provided to the script
		is the original input source file which is provided when the script
		is run for the first time. The script automatically takes care of
		resuming PAUL execution on the generated (annotated) code,
		i.e. the name of the file (generated) which contains the annotations
		need not be provided when running with the PAUL option.

	Ex: ./Blas2Cublas.py ./test.c BLAS autoAnnotNstop

		- generates rose_test.c and rose_trans_test.c (which has annotations)
		- User reviews/adds something to rose_trans_test.c
		- Then user should run ./Blas2Cublas.py ./test.c BLAS PAUL
		  - With this the script runs PAUL on rose_trans_test.c
		    and produces the transformed code.
	  

Blas2Cublas.py Usage Examples
-----------------------------

Automatically Annotated

     python $PAUL_HOME/Blas2Cublas.py $PAUL_HOME/blas2cublas/tests/blas3/cblasATLAS.c BLAS autoAnnot
(OR) python $PAUL_HOME/Blas2Cublas.py $PAUL_HOME/blas2cublas/tests/blas3/cblasMKL.c MKL autoAnnot

Manually Annotated

     python $PAUL_HOME/Blas2Cublas.py $PAUL_HOME/blas2cublas/tests/blas3/cblas1.c BLAS 
(OR) python $PAUL_HOME/Blas2Cublas.py $PAUL_HOME/blas2cublas/tests/blas3/cblas2.c MKL 


Actions performed by the Blas2Cublas.py script
----------------------------------------------

  - Assume test.c is the source file.
  - A SimpleTranslator built using ROSE processes the input file
    builds an AST and unparses it to generate rose_test.c
  - If autoAnnot option is provided rose_test.c is annotated
    and a new file rose_trans_test.c is generated with all
    BLAS calls annotated. If autoAnnot is not provided
    rose_trans_test.c would be a simple duplicate of rose_test.c
  - rose_trans_test.c is processed by PAUL and rose_trans_test_blas_calls.cocci
      is generated. This .cocci file is used by coccinelle
      to generate the final transformed code containing CUDA BLAS calls
      named rose_trans_test_cublas.cu

  NOTE: This script could be run from any location on your machine.
        All the files generated as part of the transformation are
        placed in the same directory as the original source file.


IMPORTANT NOTE FOR ATLAS LIBRARY USERS.
---------------------------------------

- If the transformed code contains a mix of regular blas calls
  and cuda blas calls and the ATLAS library is used to handle
  the regular blas calls, the header include (cblas.h) in the 
  original input code (before transformation) provided to
  the script should be wrapped using extern "C" as follows:

#ifdef __cplusplus
extern "C" {
#endif /* __cplusplus */

#include "cblas.h"

#ifdef __cplusplus
}
#endif /* __cplusplus */

  and to compile the transformed code use :

  nvcc transformedCode.cu -lcuda -lcudart -I$ATLAS_INC -L$ATLAS_LIB -lcblas -latlas -lcublas 

- This is because the host(CPU) code is compilied using gcc, but the linking buisness is
  done using g++. I am not sure if this is always the case (hence the ifdef).

See $PAUL_HOME/blas2cublas/tests/blas3/cblas1.c for an example.


Linking options
---------------

- The original user code containing BLAS calls may need to be
  linked against libraries other than BLAS which the BLAS TO
  CUDABLAS transformation is unaware of. If these options
  are provided in the file blas2cublas/linker, the transformed
  code will be compiled by the blas2cublas.py script. 

Example (also found in linker file):
% -L$ATLAS_HOME/lib -lcblas -latlas

NOTE: The line with options must start with %

- If no include and/or library paths along with other required 
  libraries are given, the transformed code is left for the user
  to be compiled.


Work in Progress
----------------

- Some more documentation in code generation.
- Complete handling routines in BLAS 1 that return values
  ( dot*, sum, nrm2, amin, amax, rot* )


Please email ajay@csc.lsu.edu with any feedback.








